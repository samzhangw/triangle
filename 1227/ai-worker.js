/**
 * ============================================
 * AI Web Worker (ai-worker.js) - Ultimate Edition
 * * ÂåÖÂê´ÊâÄÊúâ AI ÈÅãÁÆóÈÇèËºØ:
 * 1. Minimax ÊºîÁÆóÊ≥ï (Ê∑±Â∫¶Ëß£ÈéñÁâà)
 * 2. Smart Greedy (Èò≤ÂÆàÂûãË≤™Â©™)
 * 3. MCTS (Èï∑ËÄÉÁâà)
 * 4. Âü∫Âõ†ÊºîÁÆóÊ≥ïË®ìÁ∑¥Ê®°Êì¨ (Âê´Ê∫ñÁ¢∫ÁéáÈ©óË≠â)
 * ============================================
 */

// --- 1. AI Ê†∏ÂøÉËÆäÊï∏ ---
let transpositionTable = new Map();
let dots = [];
let totalTriangles = 0;
let REQUIRED_LINE_LENGTH = 1;

// ÈÅäÊà≤Ë¶èÂâá
let isScoreAndGoAgain = false; 
let isAllowShorterLines = false; // ÂÖÅË®±Áü≠ÈÄ£Á∑ö
const QUIESCENCE_MAX_DEPTH = 3;

// Ëá™Ë®ÇÊ¨äÈáç (Áî®Êñº Trained Ê®°Âºè)
let customWeights = null; 

// È†êË®≠Ê¨äÈáç (V10.0 Âº∑Â∫¶Ë®≠ÂÆö)
const DEFAULT_WEIGHTS = {
    scoreScale: 200,      // ÊèêÈ´òÂàÜÊï∏Ê¨äÈáç
    threatScale: 40,      // ÊèêÈ´òÂ®ÅËÑÖÊ¨äÈáç
    doubleSetupScale: 100, // È´òÂ∫¶ÈáçË¶ñÈõôÈáç‰ΩàÂ±Ä
    p1ThreatVal: 40,    
    p2ThreatVal: -40,
    p1DoubleVal: 100,
    p2DoubleVal: -100
};

// --- 2. Ë®äÊÅØËôïÁêÜ ---

self.onmessage = (e) => {
    const data = e.data;

    if (data.command === 'start') {
        const aiType = data.aiType || 'minimax';
        const player = data.gameState.player;
        
        // Êõ¥Êñ∞ÁãÄÊÖã
        dots = data.gameState.dots;
        totalTriangles = data.gameState.totalTriangles;
        REQUIRED_LINE_LENGTH = data.gameState.requiredLineLength;
        isScoreAndGoAgain = data.gameState.isScoreAndGoAgain; 
        isAllowShorterLines = data.gameState.allowShorterLines;
        
        if (aiType === 'trained' && data.weights) {
            customWeights = data.weights;
        } else {
            customWeights = null;
        }

        const playerName = (player === 2) ? "AI 2 (Max)" : "AI 1 (Min)";
        let bestMove;
        
        if (aiType === 'greedy') {
            logToMain(`--- [Worker] ${playerName} ‰ΩøÁî® Smart Greedy (Êô∫ÊÖßË≤™Â©™) ---`);
            transpositionTable.clear();
            bestMove = findBestGreedyMove(
                data.gameState.lines, 
                data.gameState.triangles, 
                player
            );
        } else if (aiType === 'mcts') {
            logToMain(`--- [Worker] ${playerName} ‰ΩøÁî® MCTS (Èï∑ËÄÉÊ®°Âºè) ---`);
            transpositionTable.clear();
            bestMove = findBestMCTSMove(
                data.gameState.lines,
                data.gameState.triangles,
                player
            );
        } else { 
            // Minimax Êàñ Trained
            logToMain(`--- [Worker] ${playerName} ‰ΩøÁî® Deep Minimax (Ê∑±Â∫¶ÂÖ®Èñã) ---`);
            transpositionTable.clear();
            bestMove = findBestAIMove(
                data.gameState.lines, 
                data.gameState.triangles, 
                player,
                customWeights // ÂÇ≥ÂÖ•Ëá™Ë®ÇÊ¨äÈáç
            );
        }
        
        self.postMessage({
            type: 'result',
            bestMove: bestMove
        });

    } else if (data.command === 'train_generation') {
        runTrainingGeneration(data.population, data.gameConfig);
    }
};

function logToMain(message) {
    self.postMessage({ type: 'log', message: message });
}

// --- 3. ÈÅäÊà≤ÈÇèËºØËºîÂä©ÂáΩÂºè ---
function getLineId(dot1, dot2) {
    if (!dot1 || !dot2) return null;
    let d1 = dot1, d2 = dot2;
    if (dot1.r > dot2.r || (dot1.r === dot2.r && dot1.c > dot2.c)) {
        d1 = dot2; d2 = dot1;
    }
    return `${d1.r},${d1.c}_${d2.r},${d2.c}`;
}
function isClose(val, target, tolerance = 1.5) {
    return Math.abs(val - target) < tolerance;
}
function findIntermediateDots(dotA, dotB) {
    const intermediateDots = [];
    const minX = Math.min(dotA.x, dotB.x) - 1;
    const maxX = Math.max(dotA.x, dotB.x) + 1;
    const minY = Math.min(dotA.y, dotB.y) - 1;
    const maxY = Math.max(dotA.y, dotB.y) + 1;
    const EPSILON = 1e-6; 
    dots.flat().forEach(dot => {
        if (dot.x >= minX && dot.x <= maxX && dot.y >= minY && dot.y <= maxY) {
            const crossProduct = (dotB.y - dotA.y) * (dot.x - dotB.x) - (dot.y - dotB.y) * (dotB.x - dotA.x);
            if (Math.abs(crossProduct) < EPSILON) intermediateDots.push(dot);
        }
    });
    intermediateDots.sort((a, b) => {
        if (Math.abs(a.x - b.x) > EPSILON) return a.x - b.x;
        return a.y - b.y;
    });
    return intermediateDots;
}

function isValidPreviewLine(dotA, dotB, currentLines) {
    if (!dotA || !dotB) return false;
    const dy = dotB.y - dotA.y;
    const dx = dotB.x - dotA.x;
    if (dx !== 0 || dy !== 0) {
        const angle = Math.atan2(dy, dx) * 180 / Math.PI;
        const absAngle = Math.abs(angle);
        const isValidAngle = isClose(absAngle, 0) || isClose(absAngle, 60) || isClose(absAngle, 120) || isClose(absAngle, 180);
        if (!isValidAngle) return false; 
    }
    const allDotsOnLine = findIntermediateDots(dotA, dotB);
    const segmentIds = [];
    for (let i = 0; i < allDotsOnLine.length - 1; i++) {
        segmentIds.push(getLineId(allDotsOnLine[i], allDotsOnLine[i+1]));
    }
    
    // Âà§Êñ∑Èï∑Â∫¶ÈÇèËºØ
    if (segmentIds.length === 0 && dotA !== dotB) return false;
    
    if (isAllowShorterLines) {
        // Â¶ÇÊûúÂÖÅË®±Áü≠ÈÄ£Á∑öÔºåÂè™Ë¶ÅÂ§ßÊñºÁ≠âÊñº 1 ‰∏î ‰∏çË∂ÖÈÅéË®≠ÂÆöÈï∑Â∫¶ Âç≥ÂèØ
        if (segmentIds.length < 1 || segmentIds.length > REQUIRED_LINE_LENGTH) return false;
    } else {
        // ÂéüÊúâÈÇèËºØÔºöÂøÖÈ†àÂö¥Ê†ºÁ≠âÊñº
        if (segmentIds.length !== REQUIRED_LINE_LENGTH) return false; 
    }

    let allSegmentsExist = true;
    let hasUndrawnSegment = false; 
    for (const id of segmentIds) {
        if (!id || !currentLines[id]) { allSegmentsExist = false; break; }
        if (!currentLines[id].drawn) { hasUndrawnSegment = true; }
    }
    if (!allSegmentsExist) return false; 
    if (!hasUndrawnSegment) return false; 
    return true;
}

// Âø´ÈÄüÁãÄÊÖãË§áË£Ω (Áî®Êñº MCTS È´òÈ†ªÊ®°Êì¨)
function cloneState(lines, triangles) {
    const newLines = {};
    for (const key in lines) {
        newLines[key] = { ...lines[key] };
    }
    const newTriangles = triangles.map(t => ({ ...t }));
    return { lines: newLines, triangles: newTriangles };
}

// Ê∑±Â∫¶Ë§áË£Ω (‰øùÁïôÁµ¶ÈùûÊïàËÉΩÁì∂È†∏Ëôï)
function deepCopy(obj) {
    return JSON.parse(JSON.stringify(obj));
}

// --- 4. Ë©ï‰º∞ËàáÊ®°Êì¨ÈÇèËºØ ---

function getBoardHash(lines, triangles, player) {
    let lineHash = "";
    for (const id of Object.keys(lines)) {
        if (lines[id].drawn) lineHash += `L${id}${lines[id].player}${lines[id].sharedBy};`;
    }
    let triHash = "";
    triangles.forEach((tri, idx) => {
        if (tri.filled) triHash += `T${idx}${tri.player};`;
    });
    return lineHash + triHash + `P${player}`;
}

function simulateMove(move, currentLines, currentTriangles, player) {
    // ‰ΩøÁî® cloneState ÊèêÂçáÊïàËÉΩ
    const state = cloneState(currentLines, currentTriangles);
    const newLines = state.lines;
    const newTriangles = state.triangles;
    
    let scoreGained = 0;
    let newSegmentDrawn = false;
    for (const id of move.segmentIds) {
        if (newLines[id]) { 
            if (!newLines[id].drawn) { 
                newLines[id].drawn = true;
                newLines[id].player = player;
                newSegmentDrawn = true;
            } else if (newLines[id].player !== 0 && newLines[id].player !== player) {
                if (newLines[id].sharedBy === 0) newLines[id].sharedBy = player;
            }
        }
    }
    if (!newSegmentDrawn) return null; 
    
    newTriangles.forEach(tri => {
        if (!tri.filled) {
            const isComplete = tri.lineKeys.every(key => newLines[key] && newLines[key].drawn);
            if (isComplete) {
                tri.filled = true;
                tri.player = player;
                scoreGained++;
            }
        }
    });
    return { newLines, newTriangles, scoreGained };
}

function evaluateBoard(currentLines, currentTriangles, weights) {
    const w = weights || DEFAULT_WEIGHTS;
    let p2Score = 0; // AI (Max)
    let p1Score = 0; // Human (Min)
    let p1Threats = 0; 
    let p2Threats = 0; 
    let p1DoubleSetups = 0;
    let p2DoubleSetups = 0;
    
    currentTriangles.forEach((tri, triIndex) => {
        if (tri.filled) {
            if (tri.player === 2) p2Score++;
            else p1Score++;
        } else {
            let drawnCount = 0;
            let undrawnKey = null;
            let p1Lines = 0;
            let p2Lines = 0;
            tri.lineKeys.forEach(key => {
                if (currentLines[key] && currentLines[key].drawn) {
                    drawnCount++;
                    if (currentLines[key].player === 1) p1Lines++;
                    if (currentLines[key].player === 2) p2Lines++;
                    if (currentLines[key].sharedBy === 1) p1Lines++;
                    if (currentLines[key].sharedBy === 2) p2Lines++;
                } else {
                    undrawnKey = key;
                }
            });
            if (drawnCount === 2) {
                // ÁôºÁèæÂ®ÅËÑÖ
                let completesTwo = false;
                // Ê™¢Êü•ÊòØÂê¶ÊßãÊàê Double Setup (ÈÄ£Áí∞Ë®à)
                currentTriangles.forEach((otherTri, otherTriIndex) => {
                    if (otherTriIndex !== triIndex && !otherTri.filled && otherTri.lineKeys.includes(undrawnKey)) {
                        let otherDrawnCount = 0;
                        otherTri.lineKeys.forEach(okey => {
                            if (currentLines[okey] && currentLines[okey].drawn) {
                                otherDrawnCount++;
                            }
                        });
                        if (otherDrawnCount === 2) {
                            completesTwo = true;
                        }
                    }
                });
                
                if (p1Lines > p2Lines) { 
                    p1Threats++;
                    if (completesTwo) p1DoubleSetups++;
                }
                else if (p2Lines > p1Lines) { 
                    p2Threats++;
                    if (completesTwo) p2DoubleSetups++;
                }
            }
        }
    });

    let totalFilled = p1Score + p2Score;
    if (totalFilled === totalTriangles) {
        if (p2Score > p1Score) return 1000000; 
        if (p1Score > p2Score) return -1000000;
        return 0; 
    }

    // ËÆÄÂèñÊ¨äÈáç
    const scoreVal = w.scoreScale || 200;
    const valP1T = w.p1ThreatVal || 40; 
    const valP2T = w.p2ThreatVal || -40;
    const valP1D = w.p1DoubleVal || 100; // Double Setup Ê¨äÈáç
    const valP2D = w.p2DoubleVal || -100;

    return (p2Score * scoreVal - p1Score * scoreVal) +
           (p1Threats * valP1T + p2Threats * valP2T) +
           (p1DoubleSetups * valP1D + p2DoubleSetups * valP2D) * 0.5;
}

function findAllValidMoves(currentLines) {
    const moves = [];
    const allDots = dots.flat();
    for (let i = 0; i < allDots.length; i++) {
        for (let j = i + 1; j < allDots.length; j++) {
            const dotA = allDots[i];
            const dotB = allDots[j];
            if (isValidPreviewLine(dotA, dotB, currentLines)) {
                const segmentIds = [];
                const dotsOnLine = findIntermediateDots(dotA, dotB); 
                for (let k = 0; k < dotsOnLine.length - 1; k++) {
                    segmentIds.push(getLineId(dotsOnLine[k], dotsOnLine[k+1]));
                }
                moves.push({ dot1: dotA, dot2: dotB, segmentIds: segmentIds });
            }
        }
    }
    return moves;
}

function findAllScoringMoves(currentLines, currentTriangles, player) {
    const scoringMoves = [];
    const allValidMoves = findAllValidMoves(currentLines);
    for (const move of allValidMoves) {
        let scoreGained = 0;
        const segmentIds = move.segmentIds;
        const newSegments = segmentIds.filter(id => currentLines[id] && !currentLines[id].drawn);
        if (newSegments.length === 0) continue; 
        currentTriangles.forEach(tri => {
            if (!tri.filled) {
                let missingKeys = tri.lineKeys.filter(key => !currentLines[key] || !currentLines[key].drawn);
                let allMissingKeysCovered = missingKeys.every(mKey => segmentIds.includes(mKey));
                if (missingKeys.length > 0 && allMissingKeysCovered) {
                    let otherKeysDrawn = tri.lineKeys
                        .filter(key => !missingKeys.includes(key))
                        .every(oKey => currentLines[oKey] && currentLines[oKey].drawn);
                    if (otherKeysDrawn) scoreGained++;
                }
            }
        });
        if (scoreGained > 0) scoringMoves.push(move);
    }
    return scoringMoves;
}

// ==========================================================
// üõ°Ô∏è Smart Greedy (Êô∫ÊÖßË≤™Â©™)
// ==========================================================
function findBestGreedyMove(currentLines, currentTriangles, player) {
    const allMoves = findAllValidMoves(currentLines);
    if (allMoves.length === 0) return null;

    // 1. ÂÑ™ÂÖàÔºöËÉΩÂæóÂàÜÁöÑÊ≠•
    let scoringMoves = [];
    for (const move of allMoves) {
        const sim = simulateMove(move, currentLines, currentTriangles, player);
        if (sim && sim.scoreGained > 0) {
            scoringMoves.push({ move, score: sim.scoreGained });
        }
    }
    if (scoringMoves.length > 0) {
        // ÈÅ∏ÂæóÂàÜÊúÄÂ§öÁöÑ
        scoringMoves.sort((a, b) => b.score - a.score);
        return scoringMoves[0].move;
    }

    // 2. Ê¨°Ë¶ÅÔºöÂÆâÂÖ®Ê≠• (È†êÂà§ÈÄôÊ≠•Ëµ∞ÂÆåÔºåÂ∞çÊâãÊúÉ‰∏çÊúÉÂæóÂàÜ)
    let safeMoves = [];
    let unsafeMoves = [];

    const opponent = (player === 1) ? 2 : 1;

    for (const move of allMoves) {
        const sim = simulateMove(move, currentLines, currentTriangles, player);
        if (!sim) continue;
        
        // Ê™¢Êü•Â∞çÊâãÊòØÂê¶ÊúâÂæóÂàÜÊ©üÊúÉ
        const opponentMoves = findAllScoringMoves(sim.newLines, sim.newTriangles, opponent);
        
        if (opponentMoves.length === 0) {
            safeMoves.push(move); // ÂÆâÂÖ®
        } else {
            unsafeMoves.push(move); // Âç±Èö™ (ÊúÉÈÄÅÂàÜ)
        }
    }

    if (safeMoves.length > 0) {
        return safeMoves[Math.floor(Math.random() * safeMoves.length)];
    }

    // 3. ÁÑ°Â•àÔºöÂè™ËÉΩÈÄÅÂàÜ‰∫Ü
    return unsafeMoves[Math.floor(Math.random() * unsafeMoves.length)];
}

// ==========================================================
// üå≤ MCTS (ËíôÂú∞Âç°ÁæÖÊ®πÊêúÂ∞ã - Èï∑ËÄÉÁâà)
// ==========================================================

class MCTSNode {
    constructor(state, parent = null, move = null) {
        this.state = state; 
        this.parent = parent;
        this.move = move;
        this.children = [];
        this.wins = 0;
        this.visits = 0;
        this.untriedMoves = null; 
    }

    getUCTValue(cParam = 1.414) {
        if (this.visits === 0) return Infinity;
        return (this.wins / this.visits) + cParam * Math.sqrt(Math.log(this.parent.visits) / this.visits);
    }
}

function findBestMCTSMove(initialLines, initialTriangles, rootPlayer) {
    const startTime = performance.now();
    const TIME_LIMIT = 4500; // ‚ö° Âä†Â§ßÊÄùËÄÉÊôÇÈñìËá≥ 4.5 Áßí

    // ÂàùÂßãÁãÄÊÖã
    const rootState = {
        lines: deepCopy(initialLines),
        triangles: deepCopy(initialTriangles),
        scores: { 1: 0, 2: 0 },
        currentPlayer: rootPlayer,
        filledCount: 0 
    };
    
    // Ë®àÁÆóÂàùÂßãÂàÜÊï∏
    initialTriangles.forEach(t => { if(t.filled) rootState.filledCount++; });
    let p1Init = 0, p2Init = 0;
    initialTriangles.forEach(t => { if(t.filled && t.player === 1) p1Init++; if(t.filled && t.player === 2) p2Init++; });
    rootState.scores = { 1: p1Init, 2: p2Init };

    const rootNode = new MCTSNode(rootState, null, null);
    rootNode.untriedMoves = findAllValidMoves(rootState.lines);

    let iterations = 0;
    
    while (performance.now() - startTime < TIME_LIMIT) {
        iterations++;
        let node = rootNode;
        let state = cloneState(node.state.lines, node.state.triangles);
        // ÈáçÂª∫ÂÆåÊï¥ state Áî®ÊñºÂÇ≥ÈÅû
        state = {
            lines: state.lines,
            triangles: state.triangles,
            scores: { ...node.state.scores },
            currentPlayer: node.state.currentPlayer,
            filledCount: node.state.filledCount
        };

        // 1. Selection
        while (node.untriedMoves !== null && node.untriedMoves.length === 0 && node.children.length > 0) {
            node = node.children.reduce((best, child) => {
                return child.getUCTValue() > best.getUCTValue() ? child : best;
            });
        }

        // 2. Expansion
        if (node.untriedMoves !== null && node.untriedMoves.length > 0) {
            const moveIndex = Math.floor(Math.random() * node.untriedMoves.length);
            const move = node.untriedMoves.splice(moveIndex, 1)[0];
            
            const sim = simulateMove(move, state.lines, state.triangles, state.currentPlayer);
            
            const nextState = {
                lines: sim.newLines,
                triangles: sim.newTriangles,
                scores: { ...state.scores },
                currentPlayer: state.currentPlayer,
                filledCount: state.filledCount
            };
            
            let nextPlayer = state.currentPlayer;
            if (sim.scoreGained > 0) {
                nextState.scores[state.currentPlayer] += sim.scoreGained;
                nextState.filledCount += sim.scoreGained;
                if (!isScoreAndGoAgain) {
                    nextPlayer = (state.currentPlayer === 1) ? 2 : 1;
                }
            } else {
                nextPlayer = (state.currentPlayer === 1) ? 2 : 1;
            }
            nextState.currentPlayer = nextPlayer;

            const childNode = new MCTSNode(nextState, node, move);
            childNode.untriedMoves = findAllValidMoves(nextState.lines);
            node.children.push(childNode);
            node = childNode;
            state = nextState;
        }

        // 3. Simulation (Rollout) - Âø´ÈÄüÊ®°Êì¨
        let currentLinesSim = cloneState(state.lines, state.triangles).lines; 
        let simPlayer = state.currentPlayer;
        let simScores = { ...state.scores };
        let simFilled = state.filledCount;
        
        let possibleMoves = findAllValidMoves(currentLinesSim); 
        // Èö®Ê©üÊ¥óÁâå
        for (let i = possibleMoves.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * (i + 1));
            [possibleMoves[i], possibleMoves[j]] = [possibleMoves[j], possibleMoves[i]];
        }

        let moveIdx = 0;
        // ÈôêÂà∂ Rollout Ê≠•Êï∏ÔºåÈÅøÂÖçÈÅé‰πÖ
        const MAX_ROLLOUT_STEPS = 40; 
        let steps = 0;

        while (simFilled < totalTriangles && moveIdx < possibleMoves.length && steps < MAX_ROLLOUT_STEPS) {
            const rMove = possibleMoves[moveIdx++];
            steps++;
            
            let isAlreadyDrawn = false;
            for(let sid of rMove.segmentIds) {
                if(currentLinesSim[sid] && currentLinesSim[sid].drawn) {
                    isAlreadyDrawn = true; break; 
                }
            }
            if(isAlreadyDrawn) continue;

            // Âü∑Ë°å
            const sim = simulateMove(rMove, currentLinesSim, state.triangles, simPlayer); 
            if (!sim) continue;
            
            currentLinesSim = sim.newLines;
            
            if (sim.scoreGained > 0) {
                simScores[simPlayer] += sim.scoreGained;
                simFilled += sim.scoreGained;
                if (isScoreAndGoAgain) {
                    continue; 
                }
            }
            simPlayer = (simPlayer === 1) ? 2 : 1;
        }

        // 4. Backpropagation
        let winner = 0.5;
        if (simScores[rootPlayer] > simScores[(rootPlayer===1?2:1)]) winner = 1;
        else if (simScores[rootPlayer] < simScores[(rootPlayer===1?2:1)]) winner = 0;

        while (node !== null) {
            node.visits++;
            node.wins += winner; 
            node = node.parent;
        }
    }
    
    logToMain(`MCTS ÂÆåÊàêÔºåÊ®°Êì¨Ê¨°Êï∏: ${iterations}`);

    if (rootNode.children.length === 0) return null;
    
    const bestChild = rootNode.children.reduce((best, child) => {
        return child.visits > best.visits ? child : best;
    });
    
    return bestChild.move;
}


// ==========================================================
// ‚öîÔ∏è Deep Minimax (Ê∑±Â∫¶ÂÖ®Èñã)
// ==========================================================

function quiescenceSearch(currentLines, currentTriangles, depth, isMaximizingPlayer, alpha, beta, weights) {
    const boardHash = getBoardHash(currentLines, currentTriangles, isMaximizingPlayer ? 2 : 1);
    const ttEntry = transpositionTable.get(boardHash);
    if (ttEntry && ttEntry.depth >= depth) { 
        if (ttEntry.flag === 0) return ttEntry.score;
        if (ttEntry.flag === 1) alpha = Math.max(alpha, ttEntry.score);
        if (ttEntry.flag === 2) beta = Math.min(beta, ttEntry.score);
        if (alpha >= beta) return ttEntry.score;
    }

    const standPatScore = evaluateBoard(currentLines, currentTriangles, weights);
    
    if (Math.abs(standPatScore) >= 1000000) return standPatScore;
    if (depth === 0) return standPatScore;

    let ttFlag = 0;
    const scoringMoves = findAllScoringMoves(currentLines, currentTriangles, isMaximizingPlayer ? 2 : 1);

    if (isMaximizingPlayer) { 
        let bestValue = standPatScore;
        alpha = Math.max(alpha, bestValue);
        
        if (isScoreAndGoAgain) {
            for (const move of scoringMoves) {
                const sim = simulateMove(move, currentLines, currentTriangles, 2);
                if (!sim) continue;
                const immediateScore = sim.scoreGained * 1000; 
                const futureValue = quiescenceSearch(sim.newLines, sim.newTriangles, depth - 1, true, alpha, beta, weights);
                const totalValue = immediateScore + futureValue; 
                bestValue = Math.max(bestValue, totalValue);
                alpha = Math.max(alpha, bestValue); 
                if (beta <= alpha) { ttFlag = 1; break; }
            }
        }
        transpositionTable.set(boardHash, { score: bestValue, depth: depth, flag: ttFlag });
        return bestValue;
    } else { 
        let bestValue = standPatScore;
        beta = Math.min(beta, bestValue);
        
        if (isScoreAndGoAgain) {
            for (const move of scoringMoves) {
                const sim = simulateMove(move, currentLines, currentTriangles, 1);
                if (!sim) continue;
                const immediateScore = sim.scoreGained * 1000;
                const futureValue = quiescenceSearch(sim.newLines, sim.newTriangles, depth - 1, false, alpha, beta, weights);
                const totalValue = -immediateScore + futureValue; 
                bestValue = Math.min(bestValue, totalValue);
                beta = Math.min(beta, bestValue); 
                if (beta <= alpha) { ttFlag = 2; break; }
            }
        }
        transpositionTable.set(boardHash, { score: bestValue, depth: depth, flag: ttFlag });
        return bestValue;
    }
}

function minimax(currentLines, currentTriangles, depth, isMaximizingPlayer, alpha, beta, weights) {
    const boardHash = getBoardHash(currentLines, currentTriangles, isMaximizingPlayer ? 2 : 1);
    const ttEntry = transpositionTable.get(boardHash);
    if (ttEntry && ttEntry.depth >= depth) {
        if (ttEntry.flag === 0) return ttEntry.score;
        if (ttEntry.flag === 1) alpha = Math.max(alpha, ttEntry.score);
        if (ttEntry.flag === 2) beta = Math.min(beta, ttEntry.score);
        if (alpha >= beta) return ttEntry.score;
    }
    
    const currentEval = evaluateBoard(currentLines, currentTriangles, weights);
    if (Math.abs(currentEval) >= 1000000) { 
        if (currentEval > 0) return currentEval + depth;
        return currentEval - depth;
    }
    
    const allMoves = findAllValidMoves(currentLines);
    if (depth === 0 || allMoves.length === 0) {
        return quiescenceSearch(currentLines, currentTriangles, QUIESCENCE_MAX_DEPTH, isMaximizingPlayer, alpha, beta, weights);
    }
    
    let bestValue;
    let ttFlag = 0; 

    if (isMaximizingPlayer) { 
        bestValue = -Infinity; 
        for (const move of allMoves) {
            const sim = simulateMove(move, currentLines, currentTriangles, 2); 
            if (!sim) continue;
            const immediateScore = sim.scoreGained * 1000;
            const isStillMaximizing = (isScoreAndGoAgain && sim.scoreGained > 0);
            const futureValue = minimax(sim.newLines, sim.newTriangles, depth - 1, isStillMaximizing ? true : false, alpha, beta, weights);
            const totalValue = immediateScore + futureValue; 
            bestValue = Math.max(bestValue, totalValue);
            alpha = Math.max(alpha, bestValue); 
            if (beta <= alpha) { ttFlag = 1; break; }
        }
    } else { 
        bestValue = +Infinity; 
        for (const move of allMoves) {
            const sim = simulateMove(move, currentLines, currentTriangles, 1); 
            if (!sim) continue;
            const immediateScore = sim.scoreGained * 1000; 
            const isStillMinimizing = (isScoreAndGoAgain && sim.scoreGained > 0);
            const futureValue = minimax(sim.newLines, sim.newTriangles, depth - 1, isStillMinimizing ? false : true, alpha, beta, weights); 
            const totalValue = -immediateScore + futureValue; 
            bestValue = Math.min(bestValue, totalValue);
            beta = Math.min(beta, bestValue); 
            if (beta <= alpha) { ttFlag = 2; break; }
        }
    }
    transpositionTable.set(boardHash, { score: bestValue, depth: depth, flag: ttFlag });
    return bestValue;
}

// ‚ö° Ê∑±Â∫¶Ëß£Èéñ
function getAIDepth() {
    switch (REQUIRED_LINE_LENGTH) {
        case 1: return 7; // ÂéüÊú¨ 5 -> 7
        case 2: return 7; 
        case 3: return 8; 
        case 4: case 5: return 8; 
        default: return 6; 
    }
}

/**
 * ÊâæÂá∫ÊúÄ‰Ω≥ÁßªÂãï (Deep Minimax ÂÖ•Âè£)
 */
function findBestAIMove(currentLines, currentTriangles, player, weights) {
    const isMaximizingPlayer = (player === 2);
    const MAX_DEPTH = getAIDepth();
    
    let allMoves = findAllValidMoves(currentLines); 
    if (allMoves.length === 0) return null; 

    // Move Ordering
    let scoredMoves = allMoves.map(move => {
        const sim = simulateMove(move, currentLines, currentTriangles, player);
        if (!sim) return { move, value: -Infinity }; 
        const immediateScore = sim.scoreGained * 1000;
        const futureEval = evaluateBoard(sim.newLines, sim.newTriangles, weights);
        let totalValue;
        if (isMaximizingPlayer) {
            totalValue = immediateScore + futureEval;
        } else {
            totalValue = -immediateScore + futureEval;
        }
        return { move, value: totalValue };
    });

    scoredMoves.sort((a, b) => {
        if (a.value === b.value) return Math.random() - 0.5; 
        return isMaximizingPlayer ? b.value - a.value : a.value - b.value;
    });
    
    let bestMove = null;
    let bestValue = isMaximizingPlayer ? -Infinity : +Infinity;

    // Iterative Deepening
    for (let currentDepth = 1; currentDepth <= MAX_DEPTH; currentDepth++) {
        let alpha = -Infinity;
        let beta = +Infinity;
        let currentBestMoveForDepth = null;
        let currentBestValueForDepth = isMaximizingPlayer ? -Infinity : +Infinity;

        const movesToSearch = Array.from(scoredMoves);
        if (bestMove) {
            // Â∞á‰∏ä‰∏ÄÂ±§ÊúÄÂ•ΩÁöÑÁßªÂãïÊéíÂà∞ÊúÄÂâçÈù¢
            movesToSearch.sort((a, b) => {
                const moveAId = getLineId(a.move.dot1, a.move.dot2);
                const moveBId = getLineId(b.move.dot1, b.move.dot2);
                const bestMoveId = getLineId(bestMove.dot1, bestMove.dot2);
                if (moveAId === bestMoveId) return -1;
                if (moveBId === bestMoveId) return 1;
                return 0; 
            });
        }

        for (const scoredMove of movesToSearch) {
            const move = scoredMove.move;
            const sim = simulateMove(move, currentLines, currentTriangles, player);
            if (!sim) continue; 
            const immediateScore = sim.scoreGained * 1000;
            const isStillCurrentPlayer = (isScoreAndGoAgain && sim.scoreGained > 0);
            
            const futureValue = minimax(
                sim.newLines, 
                sim.newTriangles, 
                currentDepth - 1, 
                isStillCurrentPlayer ? isMaximizingPlayer : !isMaximizingPlayer,
                alpha, 
                beta,
                weights
            );
            
            let totalMoveValue;
            if (isMaximizingPlayer) {
                totalMoveValue = immediateScore + futureValue;
                if (totalMoveValue > currentBestValueForDepth) {
                    currentBestValueForDepth = totalMoveValue;
                    currentBestMoveForDepth = move;
                }
                alpha = Math.max(alpha, currentBestValueForDepth);
            } else { 
                totalMoveValue = -immediateScore + futureValue;
                if (totalMoveValue < currentBestValueForDepth) {
                    currentBestValueForDepth = totalMoveValue;
                    currentBestMoveForDepth = move;
                }
                beta = Math.min(beta, currentBestValueForDepth);
            }
        }
        
        bestMove = currentBestMoveForDepth;
        bestValue = currentBestValueForDepth;
        
        postIntermediateResult(bestMove, currentDepth, bestValue);

        if (Math.abs(bestValue) >= (1000000 - MAX_DEPTH)) break;
    }
    return bestMove;
}

function postIntermediateResult(move, depth, score) {
    self.postMessage({
        type: 'progress',
        message: `[Worker] Ê∑±Â∫¶ ${depth} ÂÆåÊàê„ÄÇ Ë©ïÂàÜ: ${score.toFixed(0)}`,
        bestMove: move 
    });
}


// ==========================================================
// Âü∫Âõ†ÊºîÁÆóÊ≥ïË®ìÁ∑¥Ê®°Êì¨ (Âê´Ê∫ñÁ¢∫ÁéáÈ©óË≠â)
// ==========================================================

function runTrainingGeneration(population, gameConfig) {
    // 1. Êõ¥Êñ∞ÂÖ®ÂüüËÆäÊï∏
    dots = gameConfig.dots;
    totalTriangles = gameConfig.totalTriangles;
    REQUIRED_LINE_LENGTH = gameConfig.requiredLineLength;
    isScoreAndGoAgain = gameConfig.isScoreAndGoAgain;
    isAllowShorterLines = gameConfig.allowShorterLines; // [ÈáçË¶Å] ÊîØÊè¥Áü≠ÈÄ£Á∑ö
    
    // 2. ÂÖßÈÉ®Ë®ìÁ∑¥ (Agent vs Agent)
    population.forEach(agent => agent.wins = 0);

    const MATCHES_PER_AGENT = 2; 
    for (let i = 0; i < population.length; i++) {
        const agentA = population[i];
        for (let m = 0; m < MATCHES_PER_AGENT; m++) {
            let opponentIdx;
            do {
                opponentIdx = Math.floor(Math.random() * population.length);
            } while (opponentIdx === i);
            const agentB = population[opponentIdx];
            
            const winner = simulateFullGame(agentA.weights, agentB.weights, gameConfig.lines, gameConfig.triangles, false);
            
            if (winner === 1) agentA.wins++;
            else if (winner === 2) agentB.wins++; 
        }
    }

    population.forEach(agent => { agent.fitness = agent.wins; });
    population.sort((a, b) => b.fitness - a.fitness);
    const bestAgent = population[0];
    
    // [Êñ∞Â¢û] 3. Ê∫ñÁ¢∫ÁéáÈ©óË≠â (Validation): ÊúÄÂº∑ AI vs Smart Greedy
    // ÈÄ≤Ë°å 10 Â†¥Â∞çÊà∞ (ÂêÑÂÖàÊâã 5 Â†¥)ÔºåË®àÁÆóÂãùÁéá
    let validationWins = 0;
    const VALIDATION_MATCHES = 10;
    
    for (let v = 0; v < VALIDATION_MATCHES; v++) {
        const aiIsP1 = (v < VALIDATION_MATCHES / 2); // Ââç 5 Â†¥ P1, Âæå 5 Â†¥ P2
        const winner = simulateGameVsGreedy(bestAgent.weights, gameConfig.lines, gameConfig.triangles, aiIsP1);
        
        if (aiIsP1 && winner === 1) validationWins++;
        else if (!aiIsP1 && winner === 2) validationWins++;
    }
    
    const winRate = (validationWins / VALIDATION_MATCHES) * 100;

    // 4. Áî¢ÁîüÈ†êË¶ΩÊ£ãÁõ§ (Â±ïÁ§∫Áî®)
    const opponent = population[1] || population[population.length - 1]; 
    const showcaseResult = simulateFullGame(bestAgent.weights, opponent.weights, gameConfig.lines, gameConfig.triangles, true);

    self.postMessage({
        type: 'training_result',
        population: population,
        bestAgentBoard: showcaseResult.finalLines,
        // ÂõûÂÇ≥È©óË≠âÊï∏Êìö
        validationStats: {
            winRate: winRate
        }
    });
}

// [Êñ∞Â¢û] Ê®°Êì¨ÔºöÂä†Ê¨ä AI vs Smart Greedy
function simulateGameVsGreedy(aiWeights, initialLines, initialTriangles, aiIsP1) {
    let currentLines = deepCopy(initialLines);
    let currentTriangles = deepCopy(initialTriangles);
    let currentPlayer = 1;
    let scores = { 1: 0, 2: 0 };
    let filledCount = 0;
    let movesLimit = 200; 

    while (filledCount < totalTriangles && movesLimit > 0) {
        movesLimit--;
        
        let bestMove = null;
        
        // Âà§Êñ∑Áï∂ÂâçÊòØ Ë®ìÁ∑¥AI ÈÇÑÊòØ Greedy
        const isTrainingAI = (aiIsP1 && currentPlayer === 1) || (!aiIsP1 && currentPlayer === 2);
        
        if (isTrainingAI) {
            // ‰ΩøÁî®Ê¨äÈáçË©ï‰º∞ (Ê®°Êì¨ Depth=1 ÁöÑ Minimax)
            const isMaximizing = (currentPlayer === 2);
            let allMoves = findAllValidMoves(currentLines);
            if (allMoves.length === 0) break;
            
            // Èö®Ê©üÊâì‰∫ÇÔºåÈÅøÂÖçÂÉµÂåñ
            allMoves.sort(() => Math.random() - 0.5); 
            
            let bestVal = isMaximizing ? -Infinity : Infinity;
            
            for (const move of allMoves) {
                const sim = simulateMove(move, currentLines, currentTriangles, currentPlayer);
                if (!sim) continue;
                const immediateScore = sim.scoreGained * 1000;
                const boardVal = evaluateBoard(sim.newLines, sim.newTriangles, aiWeights);
                let totalVal;
                // Ê≥®ÊÑèÔºöevaluateBoard ÂõûÂÇ≥ÁöÑÊòØ (P2 - P1)ÔºåÊâÄ‰ª• Max ÂñúÊ≠°Ê≠£ÔºåMin ÂñúÊ≠°Ë≤†
                if (isMaximizing) totalVal = immediateScore + boardVal;
                else totalVal = -immediateScore + boardVal;
                
                if (isMaximizing) {
                    if (totalVal > bestVal) { bestVal = totalVal; bestMove = move; }
                } else {
                    if (totalVal < bestVal) { bestVal = totalVal; bestMove = move; }
                }
            }
        } else {
            // ‰ΩøÁî® Smart Greedy Á≠ñÁï•
            bestMove = findBestGreedyMove(currentLines, currentTriangles, currentPlayer);
        }

        if (!bestMove) break;
        
        const sim = simulateMove(bestMove, currentLines, currentTriangles, currentPlayer);
        currentLines = sim.newLines;
        currentTriangles = sim.newTriangles;
        
        if (sim.scoreGained > 0) {
            scores[currentPlayer] += sim.scoreGained;
            filledCount += sim.scoreGained;
            if (isScoreAndGoAgain) continue; 
        }
        currentPlayer = (currentPlayer === 1) ? 2 : 1;
    }
    
    return (scores[1] > scores[2]) ? 1 : ((scores[2] > scores[1]) ? 2 : 0);
}

function simulateFullGame(weightsP1, weightsP2, initialLines, initialTriangles, returnDetails = false) {
    let currentLines = deepCopy(initialLines);
    let currentTriangles = deepCopy(initialTriangles);
    let currentPlayer = 1;
    let scores = { 1: 0, 2: 0 };
    let filledCount = 0;
    let movesLimit = 200; 

    while (filledCount < totalTriangles && movesLimit > 0) {
        movesLimit--;
        const weights = (currentPlayer === 1) ? weightsP1 : weightsP2;
        const isMaximizing = (currentPlayer === 2);
        
        let allMoves = findAllValidMoves(currentLines);
        if (allMoves.length === 0) break; 
        allMoves.sort(() => Math.random() - 0.5); 
        
        let bestMove = null;
        let bestVal = isMaximizing ? -Infinity : Infinity;
        
        for (const move of allMoves) {
            const sim = simulateMove(move, currentLines, currentTriangles, currentPlayer);
            if (!sim) continue;
            const immediateScore = sim.scoreGained * 1000;
            const boardVal = evaluateBoard(sim.newLines, sim.newTriangles, weights);
            let totalVal;
            if (isMaximizing) totalVal = immediateScore + boardVal;
            else totalVal = -immediateScore + boardVal;
            if (isMaximizing) {
                if (totalVal > bestVal) { bestVal = totalVal; bestMove = move; }
            } else {
                if (totalVal < bestVal) { bestVal = totalVal; bestMove = move; }
            }
        }

        if (!bestMove) break;
        const sim = simulateMove(bestMove, currentLines, currentTriangles, currentPlayer);
        currentLines = sim.newLines;
        currentTriangles = sim.newTriangles;
        if (sim.scoreGained > 0) {
            scores[currentPlayer] += sim.scoreGained;
            filledCount += sim.scoreGained;
            if (isScoreAndGoAgain) continue; 
        }
        currentPlayer = (currentPlayer === 1) ? 2 : 1;
    }
    
    const winner = (scores[1] > scores[2]) ? 1 : ((scores[2] > scores[1]) ? 2 : 0);
    if (returnDetails) {
        return { winner: winner, finalLines: currentLines };
    }
    return winner;
}
